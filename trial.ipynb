{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.5/1.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Karthik Shetty\\Desktop\\Distributed_systems\\DS_Project\\Patent-Research-Assistant\\parse_uspto_xml.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement parse_uspto_xml (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for parse_uspto_xml\n"
     ]
    }
   ],
   "source": [
    "pip install parse_uspto_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'parse_uspto_xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsycopg2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextras\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# load the psycopg to connect to postgresql\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparse_uspto_xml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_loggers\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparse_uspto_xml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdb_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PGDBInterface\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# setup loggers\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'parse_uspto_xml'"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import datetime\n",
    "import html\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from typing import Union, Callable\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import psycopg2.extras\n",
    "\n",
    "# load the psycopg to connect to postgresql\n",
    "from parse_uspto_xml import setup_loggers\n",
    "from parse_uspto_xml.utils.db_interface import PGDBInterface\n",
    "\n",
    "\n",
    "# setup loggers\n",
    "setup_loggers.setup_root_logger()\n",
    "logger = setup_loggers.setup_file_logger(__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames_from_dir(dirpaths: list | str):\n",
    "    \"\"\"Get filenames from directory\"\"\"\n",
    "\n",
    "    if isinstance(dirpaths, str):\n",
    "        dirpaths = [dirpaths]\n",
    "\n",
    "    filenames = []\n",
    "    for dirpath in dirpaths:\n",
    "        # Load listed directories\n",
    "        if os.path.isdir(dirpath):\n",
    "            logger.info(f\"directory: {dirpath}\")\n",
    "            for filename in os.listdir(dirpath):\n",
    "                fullpath = os.path.join(dirpath, filename)\n",
    "                dir_filenames = [fullpath]\n",
    "                if os.path.isdir(fullpath):\n",
    "                    dir_filenames = get_filenames_from_dir([fullpath])\n",
    "                filenames += dir_filenames\n",
    "        else:\n",
    "            filenames += [dirpath]\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_uspto_file(bs, keep_log: bool = False):\n",
    "    \"\"\"\n",
    "    Parses a USPTO patent in a BeautifulSoup object.\n",
    "    \"\"\"\n",
    "\n",
    "    patent_office = \"uspto\"\n",
    "    grant_date = None\n",
    "    publication_num = bs['file'].split(\"-\")[0]\n",
    "    application_status = \"pending\"\n",
    "    if bs.name == ('us-patent-grant'):\n",
    "        grant_date = bs.get(\"date-produced\", None)\n",
    "        application_status = \"granted\"\n",
    "\n",
    "    publication_title = bs.find('invention-title').text\n",
    "    publication_date = bs.find('publication-reference').find('date').text\n",
    "    application_ref_bs = bs.find('application-reference')\n",
    "    application_type = application_ref_bs['appl-type']\n",
    "    application_date = application_ref_bs.find('date').text\n",
    "    application_number = application_ref_bs.find('doc-number').text\n",
    "\n",
    "    referential_documents = []\n",
    "    # {uspto_patents.publication_number,reference,cited_by_examiner,document_type,country,metadata (JSON)\n",
    "\n",
    "    related_docs_bs = bs.find(\"us-related-documents\")\n",
    "    for related_doc_bs in (related_docs_bs.find_all(recursive=False) if related_docs_bs else []):\n",
    "        related_doc = {\n",
    "            \"publication_number\": publication_num,\n",
    "            \"patent_office\": patent_office,\n",
    "            \"application_number\": application_number,\n",
    "            \"reference\": None,\n",
    "            \"cited_by_examiner\": None,\n",
    "            \"document_type\": None,\n",
    "            \"country\": None,\n",
    "            \"kind\": None,\n",
    "            \"metadata\": {}\n",
    "        }\n",
    "        if related_doc_bs.name in [\"continuation\", \"division\", \"continuation-in-part\", \"reissue\", \"substitution\", \"us-reexamination-reissue-merger\", \"continuing-reissue\"]:\n",
    "            document_type = related_doc_bs.name\n",
    "            if document_type in [\"us-reexamination-reissue-merger\", \"continuing-reissue\"]:\n",
    "                document_type = \"reissue\"\n",
    "            related_doc[\"document_type\"] = document_type\n",
    "            related_doc[\"cited_by_examiner\"] = False\n",
    "            for documents_bs in related_doc_bs.find_all(re.compile(\"(parent|child)-doc(ument)?$\")):\n",
    "                for doc_bs in documents_bs.find_all(\"document-id\"):\n",
    "                    if doc_bs.parent.name == \"parent-grant-document\":\n",
    "                        related_doc[\"reference\"] = doc_bs.find(\"doc-number\").text\n",
    "                    elif doc_bs.parent.name == \"parent-pct-document\":\n",
    "                        related_doc[\"metadata\"][\"parent_pct_number\"] = doc_bs.find(\"doc-number\").text\n",
    "                        related_doc[\"metadata\"][\"parent_pct_country\"] = doc_bs.find(\"country\").text\n",
    "                        related_doc[\"metadata\"][\"parent_pct_date\"] = getattr(doc_bs.find(\"date\"), \"text\", None)\n",
    "                    elif doc_bs.parent.name == \"parent-doc\":\n",
    "                        related_doc[\"country\"] = doc_bs.find(\"country\").text\n",
    "                        related_doc[\"metadata\"][\"application_number\"] = doc_bs.find(\"doc-number\").text\n",
    "                        related_doc[\"metadata\"][\"application_date\"] = getattr(doc_bs.find(\"date\"), \"text\", None)\n",
    "                    elif doc_bs.parent.name == \"child-doc\":\n",
    "                        related_doc[\"metadata\"][\"child_application_number\"] = doc_bs.find(\"doc-number\").text\n",
    "                        related_doc[\"metadata\"][\"parent_country\"] = doc_bs.find(\"country\").text\n",
    "        elif related_doc_bs.name in [\"us-provisional-application\"]:\n",
    "            related_doc[\"document_type\"] = \"provisional\"\n",
    "            related_doc[\"cited_by_examiner\"] = False\n",
    "            related_doc[\"country\"] = related_doc_bs.find(\"country\").text\n",
    "            related_doc[\"reference\"] = related_doc_bs.find(\"doc-number\").text\n",
    "            related_doc[\"metadata\"][\"application_date\"] = related_doc_bs.find(\"date\").text\n",
    "        elif related_doc_bs.name in [\"related-publication\"]:\n",
    "            related_doc[\"document_type\"] = \"prior\"\n",
    "            related_doc[\"cited_by_examiner\"] = False\n",
    "            related_doc[\"reference\"] = related_doc_bs.find(\"doc-number\").text\n",
    "            related_doc[\"country\"] = related_doc_bs.find(\"country\").text\n",
    "            related_doc[\"kind\"] = related_doc_bs.find(\"kind\").text\n",
    "            related_doc[\"metadata\"][\"date\"] = related_doc_bs.find(\"date\").text\n",
    "        else:\n",
    "            raise KeyError(f\"'{related_doc_bs.name}' is not setup to be included in referential documents.\")\n",
    "        referential_documents.append(related_doc)\n",
    "\n",
    "    references = []\n",
    "    refs_cited_bs = bs.find(re.compile(\".*-references-cited\"))\n",
    "    if refs_cited_bs:\n",
    "        for ref_bs in refs_cited_bs.find_all(re.compile(\".*-citation\")):\n",
    "            doc_bs = ref_bs.find(\"document-id\")\n",
    "            if doc_bs:\n",
    "                reference = {\n",
    "                    \"publication_number\": publication_num,\n",
    "                    \"patent_office\": patent_office,\n",
    "                    \"application_number\": application_number,\n",
    "                    \"reference\": doc_bs.find(\"doc-number\").text,\n",
    "                    \"cited_by_examiner\": \"examiner\" in ref_bs.find(\"category\").text,\n",
    "                    \"document_type\": \"patent-reference\",\n",
    "                    \"country\": getattr(doc_bs.find(\"country\"), \"text\", None),\n",
    "                    \"kind\": getattr(doc_bs.find(\"kind\"), \"text\", None),\n",
    "                    \"metadata\":{\n",
    "                        \"name\": getattr(doc_bs.find(\"name\"), \"text\", None),\n",
    "                        \"date\": getattr(doc_bs.find(\"date\"), \"text\", None),\n",
    "                    }\n",
    "                }\n",
    "            else:\n",
    "                reference = {\n",
    "                    \"publication_number\": publication_num,\n",
    "                    \"patent_office\": patent_office,\n",
    "                    \"application_number\": application_number,\n",
    "                    \"reference\": ref_bs.find(\"othercit\").text,\n",
    "                    \"cited_by_examiner\": \"examiner\" in ref_bs.find(\"category\").text,\n",
    "                    \"document_type\": \"other-reference\",\n",
    "                    \"country\": getattr(ref_bs.find(\"country\"), \"text\", None),\n",
    "                    \"kind\": None,\n",
    "                    \"metadata\": {},\n",
    "                }\n",
    "            references.append(reference)\n",
    "        referential_documents += references\n",
    "\n",
    "    priority_claims = []\n",
    "    priority_docs_bs = bs.find(\"priority-claims\")\n",
    "    if priority_docs_bs:\n",
    "        for doc_bs in priority_docs_bs.find_all(\"priority-claim\"):\n",
    "            priority_claims.append({\n",
    "                \"publication_number\": publication_num,\n",
    "                \"patent_office\": patent_office,\n",
    "                \"application_number\": application_number,\n",
    "                \"reference\": doc_bs.find(\"doc-number\").text,\n",
    "                \"cited_by_examiner\": False,\n",
    "                \"document_type\": \"other-reference\",\n",
    "                \"country\": getattr(doc_bs.find(\"country\"), \"text\", None),\n",
    "                \"kind\": None,\n",
    "                \"metadata\":{\n",
    "                    \"date\": getattr(doc_bs.find(\"date\"), \"text\", None),\n",
    "                },\n",
    "            })\n",
    "        referential_documents += priority_claims\n",
    "\n",
    "    # check to make sure all keys are proper -- TODO: this should be a test.\n",
    "    for reference in referential_documents:\n",
    "        expected_keys = {\n",
    "            \"publication_number\",\n",
    "            \"patent_office\",\n",
    "            \"application_number\",\n",
    "            \"reference\",\n",
    "            \"cited_by_examiner\",\n",
    "            \"document_type\",\n",
    "            \"country\",\n",
    "            \"kind\",\n",
    "            \"metadata\",\n",
    "        }\n",
    "        missing_keys = expected_keys - set(reference.keys())\n",
    "        bad_keys =  set(reference.keys()) - expected_keys\n",
    "        if missing_keys or bad_keys:\n",
    "            raise KeyError(\n",
    "                f\"referential_documents has missing_keys: \"\n",
    "                f\"{missing_keys} and bad_keys: {bad_keys} \"\n",
    "                f\"for {reference}\"\n",
    "            )\n",
    "\n",
    "    # International Patent Classification (IPC) Docs:\n",
    "    # https://www.wipo.int/classifications/ipc/en/\n",
    "    sections = {}\n",
    "    section_classes = {}\n",
    "    section_class_subclasses = {}\n",
    "    section_class_subclass_groups = {}\n",
    "    for classes in bs.find_all('classifications-ipcr'):\n",
    "        for el in classes.find_all('classification-ipcr'):\n",
    "\n",
    "            section = el.find('section').text\n",
    "\n",
    "            classification  = section\n",
    "            classification += el.find('class').text\n",
    "            classification += el.find('subclass').text\n",
    "\n",
    "            group = el.find('main-group').text + \"/\"\n",
    "            group += el.find('subgroup').text\n",
    "\n",
    "            sections[section] = True\n",
    "            section_classes[section+el.find('class').text] = True\n",
    "            section_class_subclasses[classification] = True\n",
    "            section_class_subclass_groups[classification+\" \"+group] = True\n",
    "\n",
    "    if not sections:\n",
    "        re_classification = re.compile(\n",
    "            \"(?P<section>[A-Z])\"\n",
    "            + \"(?P<class>[0-9]{2})\"\n",
    "            + \"(?P<subclass>[A-Z])\"\n",
    "            + \"\\s?(?P<maingroup>[0-9]{1,4})\"\n",
    "            + \"\\s?/\\s?\"\n",
    "            + \"(?P<subgroup>[0-9]{2,6})\"\n",
    "        )\n",
    "        re_classification_tag = re.compile(\n",
    "            \"(classification-ipc(r)?)|(classification-cpc(-text)?)\"\n",
    "        )\n",
    "        for classes in bs.find_all(re.compile(\"us-bibliographic-data-(grant|application)\")):\n",
    "            for el in classes.find_all(re_classification_tag):\n",
    "                if \"citation\" in el.parent.name:\n",
    "                    continue  # skip anything that's not the patent itself\n",
    "                classification = getattr(el.find('main-classification'), \"text\", el.text)\n",
    "                re_value = re_classification.match(classification)\n",
    "                if re_value is not None:\n",
    "                    section = re_value.group(\"section\")\n",
    "                    section_class = section + re_value.group(\"class\")\n",
    "                    section_subclass = section_class + re_value.group(\"subclass\")\n",
    "\n",
    "                    group = re_value.group(\"maingroup\") + \"/\" + re_value.group(\"subgroup\")\n",
    "\n",
    "                    sections[section] = True\n",
    "                    section_classes[section_class] = True\n",
    "                    section_class_subclasses[section_subclass] = True\n",
    "                    section_class_subclass_groups[section_subclass + \" \" + group] = True\n",
    "\n",
    "    def build_name(bs_el):\n",
    "        \"\"\"Creates a name '<First> <Last>'\"\"\"\n",
    "        # [First Name, Last Name]\n",
    "        name_builder = []\n",
    "        for attr_name in [\"first-name\", \"last-name\"]:\n",
    "            value = getattr(bs_el.find(attr_name), \"text\", \"\")\n",
    "            if value and value != \"unknown\":\n",
    "                name_builder.append(value)\n",
    "        name = \"\"\n",
    "        if name_builder:\n",
    "            name = \" \".join(name_builder).strip()\n",
    "        return name\n",
    "\n",
    "    def build_org(bs_el):\n",
    "        \"\"\"Creates an organization '<org>, <city>, <country>'\"\"\"\n",
    "        # org_builder: [organization, city, country]\n",
    "        org_builder = []\n",
    "        for attr_name in [\"orgname\", \"city\", \"country\"]:\n",
    "            value = getattr(bs_el.find(attr_name), \"text\", \"\")\n",
    "            if value and value != \"unknown\":\n",
    "                org_builder.append(value)\n",
    "        org_name = \"\"\n",
    "        if org_builder:\n",
    "            org_name = \", \".join(org_builder).strip()\n",
    "        return org_name\n",
    "\n",
    "    authors = []\n",
    "    organizations = []\n",
    "    attorneys = []\n",
    "    attorney_organizations = []\n",
    "    for parties in bs.find_all(re.compile('^.*parties')):\n",
    "        for inventors in parties.find_all(re.compile('inventors|applicants')):\n",
    "            for el in inventors.find_all('addressbook'):\n",
    "                # inventor_name: \" \".join([first, last])\n",
    "                inventor_name = build_name(el)\n",
    "                if inventor_name:\n",
    "                    authors.append(inventor_name)\n",
    "\n",
    "        for applicants in parties.find_all(re.compile('^.*applicants')):\n",
    "            for el in applicants.find_all('addressbook'):\n",
    "                # org_name: \", \".join([organization, city, country])\n",
    "                org_name = build_org(el)\n",
    "                if org_name:\n",
    "                    organizations.append(org_name)\n",
    "\n",
    "        for agents in parties.find_all(re.compile('^.*agents')):\n",
    "            for agent in agents.find_all(\"agent\", attrs={\"rep-type\": \"attorney\"}):\n",
    "                for el in agent.find_all(\"addressbook\"):\n",
    "                    # attorney_name: \" \".join([first, last])\n",
    "                    attorney_name = build_name(el)\n",
    "                    if attorney_name:\n",
    "                        attorneys.append(attorney_name)\n",
    "\n",
    "                    # org_name: \", \".join([organization, city, country])\n",
    "                    org_name = build_org(el)\n",
    "                    if org_name:\n",
    "                        attorney_organizations.append(org_name)\n",
    "\n",
    "    abstracts = []\n",
    "    for el in bs.find_all('abstract'):\n",
    "        abstracts.append(el.text.strip('\\n'))\n",
    "\n",
    "    descriptions = []\n",
    "    for el in bs.find_all('description'):\n",
    "        descriptions.append(el.text.strip('\\n'))\n",
    "\n",
    "    claims = []\n",
    "    for el in bs.find_all('claim'):\n",
    "        claims.append(el.text.strip('\\n'))\n",
    "\n",
    "    uspto_patent = {\n",
    "        \"publication_title\": publication_title,\n",
    "        \"publication_number\": publication_num,\n",
    "        \"publication_date\": publication_date,\n",
    "        \"grant_date\": grant_date,\n",
    "        \"application_number\": application_number,\n",
    "        \"application_type\": application_type,\n",
    "        \"application_date\": application_date,\n",
    "        \"application_status\": application_status,\n",
    "        \"patent_office\": patent_office,\n",
    "        \"authors\": authors, # list\n",
    "        \"organizations\": organizations, # list\n",
    "        \"attorneys\": attorneys, # list\n",
    "        \"attorney_organizations\": attorney_organizations, # list\n",
    "        \"referential_documents\": referential_documents,\n",
    "        \"sections\": list(sections.keys()),\n",
    "        \"section_classes\": list(section_classes.keys()),\n",
    "        \"section_class_subclasses\": list(section_class_subclasses.keys()),\n",
    "        \"section_class_subclass_groups\": list(section_class_subclass_groups.keys()),\n",
    "        \"abstract\": abstracts, # list\n",
    "        \"descriptions\": descriptions, # list\n",
    "        \"claims\": claims # list\n",
    "    }\n",
    "\n",
    "    if keep_log:\n",
    "\n",
    "        print(\"Filename:\", bs['file'])\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"\\n--------------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"USPTO Invention Title:\", publication_title)\n",
    "        print(\"USPTO Publication Number:\", publication_num)\n",
    "        print(\"USPTO Publication Date:\", publication_date)\n",
    "        print(\"USPTO Application Type:\", application_type)\n",
    "\n",
    "        count = 1\n",
    "        for classification in section_class_subclass_groups:\n",
    "            print(\"USPTO Classification #\"+str(count)+\": \" + classification)\n",
    "            count += 1\n",
    "        print(\"\\n\")\n",
    "\n",
    "        count = 1\n",
    "        for author in authors:\n",
    "            print(\"Inventor #\"+str(count)+\": \" + author)\n",
    "            count += 1\n",
    "\n",
    "        count = 1\n",
    "        for org in organizations:\n",
    "            print(\"Organization #\"+str(count)+\": \" + org)\n",
    "            count += 1\n",
    "\n",
    "        count = 1\n",
    "        for attorney in attorneys:\n",
    "            print(\"Attorney #\"+str(count)+\": \" + attorney)\n",
    "            count += 1\n",
    "\n",
    "        count = 1\n",
    "        for org in attorney_organizations:\n",
    "            print(\"Attorney Organization #\"+str(count)+\": \" + org)\n",
    "            count += 1\n",
    "\n",
    "        print(\"\\n--------------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"Abstract:\\n-----------------------------------------------\")\n",
    "        for abstract in abstracts:\n",
    "            print(abstract)\n",
    "\n",
    "        print(\"Description:\\n-----------------------------------------------\")\n",
    "        for description in descriptions:\n",
    "            print(description)\n",
    "\n",
    "        print(\"Claims:\\n-----------------------------------------------\")\n",
    "        for claim in claims:\n",
    "            print(claim)\n",
    "\n",
    "    return uspto_patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_patent_to_db(patents, patent_table_name, db=None):\n",
    "\n",
    "    \"\"\"\n",
    "    import pprint\n",
    "    pp = pprint.PrettyPrinter(indent=2)\n",
    "    for key in uspto_patent:\n",
    "        if type(uspto_patent[key]) == list:\n",
    "            if key == \"section_class_subclass_groups\":\n",
    "                print(\"\\n--------------------------------\")\n",
    "                print(uspto_patent['publication_title'])\n",
    "                print(uspto_patent['publication_number'])\n",
    "                print(uspto_patent['publication_date'])\n",
    "                print(uspto_patent['sections'])\n",
    "                print(uspto_patent['section_classes'])\n",
    "                print(uspto_patent['section_class_subclasses'])\n",
    "                print(uspto_patent['section_class_subclass_groups'])\n",
    "                print(\"--------------------------------\")\n",
    "    \"\"\"\n",
    "\n",
    "    db_cursor = None\n",
    "    if db is not None:\n",
    "        db_cursor = db.obtain_db_cursor()\n",
    "\n",
    "    if db_cursor is None:\n",
    "        return\n",
    "\n",
    "    columns = [\n",
    "        \"publication_title\",\n",
    "        \"publication_number\",\n",
    "        \"publication_date\",\n",
    "        \"publication_type\",\n",
    "        \"grant_date\",\n",
    "        \"application_number\",\n",
    "        \"application_date\",\n",
    "        \"application_status\",\n",
    "        \"patent_office\",\n",
    "        \"authors\",\n",
    "        \"organizations\",\n",
    "        \"attorneys\",\n",
    "        \"attorney_organizations\",\n",
    "        \"sections\",\n",
    "        \"section_classes\",\n",
    "        \"section_class_subclasses\",\n",
    "        \"section_class_subclass_groups\",\n",
    "        \"abstract\",\n",
    "        \"description\",\n",
    "        \"claims\",\n",
    "        \"created_at\",\n",
    "        \"updated_at\",\n",
    "    ]\n",
    "    read_only_cols = {\"created_at\"}\n",
    "    conflict_columns = {\"application_number\", \"patent_office\"}\n",
    "    updateable_cols = set(columns).difference(conflict_columns).difference(read_only_cols)\n",
    "    newer_than_col = \"publication_date\"\n",
    "\n",
    "    def tuple_creator(values):\n",
    "        n_values = len(values)\n",
    "        format_str = ', '.join([\"\\\"{}\\\"\"] * n_values)\n",
    "        return f\"({format_str})\".format(*values)\n",
    "\n",
    "    def jsonify_dicts(value):\n",
    "        if isinstance(value, dict):\n",
    "            return json.dumps(value)\n",
    "        return value\n",
    "\n",
    "    def get_data_for_column(data, column):\n",
    "        if column in [\"created_at\", \"updated_at\"]:\n",
    "            return current_time\n",
    "        elif column in [\"publication_type\"]:\n",
    "            return data.get(\"application_type\")\n",
    "        elif column in [\"abstract\", \"description\", \"claims\"]:\n",
    "            if column == \"description\":\n",
    "                column = \"descriptions\"\n",
    "            return '\\n'.join(data.get(column))\n",
    "        elif column in [\n",
    "            \"authors\", \"organizations\", \"attorneys\", \"attorney_organizations\",\n",
    "            \"sections\", \"section_classes\", \"section_class_subclasses\",\n",
    "            \"section_class_subclass_groups\",\n",
    "        ]:\n",
    "            return ','.join(data.get(column))\n",
    "        return data.get(column)\n",
    "\n",
    "    exclude_set_string = \"({})\".format(\", \".join([\n",
    "        \"EXCLUDED.{:s}\".format(col) for col in updateable_cols\n",
    "    ]))\n",
    "    newer_than_only = \"\"\n",
    "    if newer_than_col:\n",
    "        newer_than_only = f\"WHERE EXCLUDED.{newer_than_col} > {patent_table_name}.{newer_than_col}\"\n",
    "\n",
    "    # Will use for created_at & updated_at time\n",
    "    current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    psycopg2.extras.execute_values(\n",
    "        db_cursor,\n",
    "        f\"\"\"INSERT INTO {patent_table_name} {tuple_creator(columns)}\n",
    "                VALUES\n",
    "                    %s\n",
    "                ON CONFLICT {tuple_creator(conflict_columns)} DO UPDATE\n",
    "                SET {tuple_creator(updateable_cols)} = {exclude_set_string}\n",
    "                {newer_than_only}\"\"\",\n",
    "        [\n",
    "            [ jsonify_dicts(get_data_for_column(data, column)) for column in columns ]\n",
    "                for data in patents\n",
    "        ]\n",
    "    )\n",
    "    logger.debug(f\"DB UPSERT message: {db_cursor.statusmessage}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_referential_documents_to_db(document_list, db=None):\n",
    "    \"\"\"\"\"\"\n",
    "    # Will use for created_at & updated_at time\n",
    "    current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "    db_cursor = None\n",
    "    if db is not None:\n",
    "        db_cursor = db.obtain_db_cursor()\n",
    "\n",
    "    if db_cursor is None:\n",
    "        return\n",
    "\n",
    "    columns = [\n",
    "        \"uspto_publication_number\",\n",
    "        \"reference\",\n",
    "        \"cited_by_examiner\",\n",
    "        \"document_type\",\n",
    "        \"country\",\n",
    "        \"metadata\",\n",
    "        \"kind\",\n",
    "        \"created_at\",\n",
    "        \"updated_at\",\n",
    "    ]\n",
    "    # read_only_cols = {\"created_at\"}\n",
    "    # conflict_columns = {\"uspto_publication_number\", \"reference\", \"document_type\", \"country\", \"kind\"}\n",
    "    # updateable_cols = set(columns).difference(conflict_columns).difference(read_only_cols)\n",
    "    # conflict_columns = {\"uspto_publication_number\", \"reference\", \"document_type\", \"country\", \"kind\"}\n",
    "\n",
    "    def tuple_creator(values):\n",
    "        n_values = len(values)\n",
    "        format_str = ', '.join([\"\\\"{}\\\"\"] * n_values)\n",
    "        return f\"({format_str})\".format(*values)\n",
    "\n",
    "    def jsonify_dicts(value):\n",
    "        if isinstance(value, dict):\n",
    "            return json.dumps(value)\n",
    "        return value\n",
    "\n",
    "    def get_data_for_column(data, column):\n",
    "        if column in [\"created_at\", \"updated_at\"]:\n",
    "            return current_time\n",
    "        return data.get(column)\n",
    "\n",
    "    # exclude_set_string = \"({})\".format(\", \".join([\n",
    "    #     \"EXCLUDED.{:s}\".format(col) for col in updateable_cols\n",
    "    # ]))\n",
    "\n",
    "    psycopg2.extras.execute_values(\n",
    "        db_cursor,\n",
    "        f\"\"\"INSERT INTO uspto_referential_documents {tuple_creator(columns)}\n",
    "                VALUES\n",
    "                    %s\n",
    "                ON CONFLICT DO NOTHING\"\"\",\n",
    "                # ON CONFLICT {tuple_creator(conflict_columns)} DO UPDATE\n",
    "                # SET {tuple_creator(updateable_cols)} = {exclude_set_string}\"\"\",\n",
    "        [\n",
    "            [ jsonify_dicts(get_data_for_column(data, column)) for column in columns ]\n",
    "                for data in document_list\n",
    "        ]\n",
    "    )\n",
    "    logger.debug(f\"DB UPSERT message: {db_cursor.statusmessage}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch_from_data(\n",
    "        xml_text_list: list[str],\n",
    "        keep_log: bool = False\n",
    "    ):\n",
    "\n",
    "    count = 0\n",
    "    success_count = 0\n",
    "    errors = []\n",
    "    patent_list = []\n",
    "\n",
    "    for patent in xml_text_list:\n",
    "\n",
    "        if patent is None or patent == \"\":\n",
    "            continue\n",
    "\n",
    "        bs = BeautifulSoup(patent, \"lxml\")\n",
    "\n",
    "        if bs.find('sequence-cwu') is not None:\n",
    "            continue # Skip DNA sequence documents\n",
    "\n",
    "        application = bs.find('us-patent-application')\n",
    "        if application is None: # If no application, search for grant\n",
    "            application = bs.find('us-patent-grant')\n",
    "        title = \"None\"\n",
    "\n",
    "        try:\n",
    "            title = application.find('invention-title').text\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error at {count}: {str(e)}\", e)\n",
    "\n",
    "        try:\n",
    "            uspto_patent = parse_uspto_file(\n",
    "                bs=application,\n",
    "                keep_log=keep_log\n",
    "            )\n",
    "            patent_list.append(uspto_patent)\n",
    "            success_count += 1\n",
    "        except Exception as e:\n",
    "            exception_tuple = (count, title, e)\n",
    "            errors.append(exception_tuple)\n",
    "            logger.error(f\"Error: {exception_tuple}\", exc_info=True)\n",
    "        count += 1\n",
    "\n",
    "    return count, success_count, patent_list, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_data(\n",
    "        xml_text: str,\n",
    "        filename: str,\n",
    "        push_to_func: Callable,\n",
    "        batch_size: int = 50,\n",
    "        max_patents: int | None = None,\n",
    "        keep_log: bool = False\n",
    "    ):\n",
    "\n",
    "    count = 0\n",
    "    success_count = 0\n",
    "    errors = []\n",
    "\n",
    "    xml_splits = xml_text.split(\"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\")\n",
    "    if len(xml_splits) and not xml_splits[0]:\n",
    "        xml_splits = xml_splits[1:]\n",
    "    for i in range(0, len(xml_splits), batch_size):\n",
    "\n",
    "        last_index = i + batch_size\n",
    "        if max_patents:\n",
    "            last_index = min(max_patents, i + batch_size)\n",
    "\n",
    "        xml_batch = xml_splits[i : last_index]\n",
    "        batch_count, batch_success_count, patents, batch_errors = \\\n",
    "            load_batch_from_data(xml_batch, keep_log)\n",
    "        count += batch_count\n",
    "\n",
    "        recent_title = None\n",
    "        if len(patents):\n",
    "            recent_title = patents[0].get(\"publication_title\")\n",
    "\n",
    "        try:\n",
    "            push_to_func(patents)\n",
    "            logger.info(f\"{count}, {filename}, {recent_title}\")\n",
    "        except Exception as e:\n",
    "            exception_tuple = (count, recent_title, e)\n",
    "            errors.append(exception_tuple)\n",
    "            logger.error(f\"Error: {exception_tuple}\", exc_info=True)\n",
    "            batch_success_count = 0\n",
    "\n",
    "        success_count += batch_success_count\n",
    "        errors += batch_errors\n",
    "\n",
    "        if max_patents is not None and count >= max_patents:\n",
    "            break\n",
    "\n",
    "    return count, success_count, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_local_files(\n",
    "        dirpath_list:  list,\n",
    "        push_to_func: Callable,\n",
    "        limit_per_file: Union[int, None] = None,\n",
    "        batch_size: int = 50,\n",
    "        keep_log: bool = False,\n",
    "):\n",
    "    \"\"\"Load all files from local directory\"\"\"\n",
    "    logger.info(\"LOADING FILES TO PARSE\\n----------------------------\")\n",
    "    filenames = get_filenames_from_dir(dirpath_list)\n",
    "\n",
    "    count = 0\n",
    "    success_count = 0\n",
    "    errors = []\n",
    "    for filename in filenames:\n",
    "        if not filename.endswith(\".xml\"):\n",
    "            continue\n",
    "\n",
    "        with open(filename, \"r\") as fp:\n",
    "            xml_text = html.unescape(fp.read())\n",
    "\n",
    "        batch_count, batch_success_count, batch_errors = load_from_data(\n",
    "            xml_text,\n",
    "            filename,\n",
    "            push_to_func,\n",
    "            batch_size,\n",
    "            max_patents=limit_per_file,\n",
    "            keep_log=keep_log,\n",
    "        )\n",
    "        count += batch_count\n",
    "        success_count += batch_success_count\n",
    "        errors += batch_errors\n",
    "\n",
    "    if errors:\n",
    "        logger.error(\"\\n\\nErrors\\n------------------------\\n\")\n",
    "        for e in errors:\n",
    "            logger.error(e)\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(f\"Success Count: {success_count}\")\n",
    "    logger.info(f\"Error Count: {count - success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_jsonl(patents: list[dict], push_to: str):\n",
    "    patent_dumps_list = []\n",
    "    for uspto_patent in patents:\n",
    "        patent_dumps_list.append(json.dumps(uspto_patent) + \"\\n\")\n",
    "    with open(push_to, \"a\") as fp:\n",
    "        fp.writelines(patent_dumps_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_db(\n",
    "        patents: list[dict],\n",
    "        push_to: PGDBInterface,\n",
    "        patent_table_name: str,\n",
    "        include_referential: bool = True,\n",
    "    ):\n",
    "    write_patent_to_db(patents, patent_table_name, db=push_to)\n",
    "    if include_referential:\n",
    "        for uspto_patent in patents:\n",
    "            write_referential_documents_to_db(\n",
    "                uspto_patent[\"referential_documents\"], db=push_to\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dump_function(push_to, *args, **kwargs):\n",
    "    if isinstance(push_to, str) and push_to.endswith(\".jsonl\"):\n",
    "        return lambda x: push_to_jsonl(x, push_to)\n",
    "    elif isinstance(push_to, PGDBInterface):\n",
    "        return lambda x: push_to_db(x, push_to, *args, **kwargs)\n",
    "    else:\n",
    "        push_to_error = (\n",
    "            f\"push_to: `{str(push_to)}` is not valid.\"\n",
    "            \" must be a str ending in 'jsonl' or a PGDBInterface.\"\n",
    "        )\n",
    "        logger.error(push_to_error)\n",
    "        raise ValueError(push_to_error)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _arg_filenames = []\n",
    "    if len(sys.argv) > 1:\n",
    "        _arg_filenames = sys.argv[1:]\n",
    "\n",
    "    _db_config_file = \"config/postgres.tsv\"\n",
    "    _db = PGDBInterface(config_file=_db_config_file)\n",
    "    _db.silent_logging = True\n",
    "    _push_to = _db\n",
    "    _patent_table_name = \"uspto_patents\"\n",
    "\n",
    "    _push_to_func = get_dump_function(\n",
    "        _push_to,\n",
    "        patent_table_name=_patent_table_name,\n",
    "        include_referential=True\n",
    "    )\n",
    "\n",
    "    load_local_files(\n",
    "        dirpath_list=_arg_filenames,\n",
    "        push_to_func=_push_to_func,\n",
    "        batch_size=50,\n",
    "        limit_per_file=None,\n",
    "        keep_log=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
